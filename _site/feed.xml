<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.4">Jekyll</generator><link href="//numerairx.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="//numerairx.github.io/" rel="alternate" type="text/html" /><updated>2019-02-12T19:47:44-05:00</updated><id>//numerairx.github.io/feed.xml</id><title type="html">NumerairX</title><subtitle>Periodic Quant Struggles</subtitle><entry><title type="html">Bayesian struggles Black Litterman Bayes Walkthrough Part 1</title><link href="//numerairx.github.io/Bayesian-Struggles-Black-Litterman-Bayes-Walkthrough-Part-1/" rel="alternate" type="text/html" title="Bayesian struggles Black Litterman Bayes Walkthrough Part 1" /><published>2019-02-11T00:00:00-05:00</published><updated>2019-02-11T00:00:00-05:00</updated><id>//numerairx.github.io/Bayesian%20Struggles-Black-Litterman-Bayes-Walkthrough-Part%201</id><content type="html" xml:base="//numerairx.github.io/Bayesian-Struggles-Black-Litterman-Bayes-Walkthrough-Part-1/">&lt;p&gt;The beauty of mathematics, to me, lies the most in the ability of substantiating abstract ideas. One of my favorite to name is the orbit-stabilizer theorem (imaginable as a cube with orbit and you can flip it by rules).&lt;/p&gt;

&lt;p&gt;The beauty of financial mathematics on the other hand, lies the most in everything comes down to a set of procedures all the time (uniformity!). For Black-Litterman optimization, it is falls under the category of statistical procedure, where we assume return follows a distribution, and portfolio managers’ economics views are useful to infer the parameters of the distribution given our objective expectation.&lt;/p&gt;

&lt;p&gt;Before we start, I want to acknowledge that everything I learned in this post was again, from my wonderful professor Gordon Ritter at his very amazing class Active Portfolio Management (I think available at NYU tandon and Baruch MFE program). This particular class was taken from his paper with Professor Petter Kolm (who I always see him being very excited about math details). Please read &lt;a href=&quot;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2853158&quot;&gt;their paper&lt;/a&gt; if you are interested in learning deeper (for example, the consideration on choosing prior)!&lt;/p&gt;

&lt;h6 id=&quot;intuitions-on-black-litterman-bayes&quot;&gt;Intuitions on Black-Litterman-Bayes&lt;/h6&gt;

&lt;p&gt;Objective: find optimized holdings of our portfolio s.t. $ h* = argmax_h {E[h’r] - \frac{2}V[h’r] }$&lt;/p&gt;

&lt;p&gt;Translation: Need to estimate mean and variance of $r$ to solve mean-variance optimization&lt;/p&gt;

&lt;p&gt;Elements needed:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Unconditional expectation and variance of $r$ to get posterior update $r \sim  N(\theta,\sum)$&lt;/li&gt;
  &lt;li&gt;$r$’s conjugate prior, let $\theta \sim N(\Pi,C)$&lt;/li&gt;
  &lt;li&gt;priori optimal portfolio holding $h_b$&lt;/li&gt;
&lt;/ul&gt;

&lt;h6 id=&quot;bayesian-set-up&quot;&gt;Bayesian Set Up&lt;/h6&gt;

&lt;p&gt;Imagine we have some portfolios, and N portfolio managers has opinion on what sector might outperform all other sectors by a percentage, $q%$. Then essentially the holdings on portfolio of each manager makes up a matrix $P$ of N rows and each row is a set of holdings. Then our expected return on the whole portfolio equals to $q$.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;on a detailed level, we have $E(p_ir) = q_i$ for $q_i$ in $\mathbb{R}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Importantly, we specify error for each expectation, for which we will denote as $\epsilon_i \sim N(0, \Omega)$ and thus we have a likelihood to maximize.&lt;/p&gt;

&lt;p&gt;Our calculation steps then follow:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;calculate posterior of $\theta$: $p(\theta&lt;/td&gt;
          &lt;td&gt;q) = \frac{f(q&lt;/td&gt;
          &lt;td&gt;\theta)\pi(\theta)}{\int{f(q&lt;/td&gt;
          &lt;td&gt;\theta)\pi(\theta)}}$                                                      (1)&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;use the above to calculate the posterior of $r$: $p(r&lt;/td&gt;
          &lt;td&gt;q) = \int{p(r&lt;/td&gt;
          &lt;td&gt;\theta)p(\theta&lt;/td&gt;
          &lt;td&gt;q)d\theta} $     (2)&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;use the mean and variance of posterior of r to calculate $h_{opt}$                        (3)&lt;/li&gt;
&lt;/ol&gt;

&lt;h6 id=&quot;posterior-of-theta&quot;&gt;Posterior of $\theta$&lt;/h6&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Very obviously we can approximate the posterior to $N(q&lt;/td&gt;
      &lt;td&gt;p\theta,\Omega)* N(\theta&lt;/td&gt;
      &lt;td&gt;\Pi,\Omega)$ according to (1) (question to readers, think about why are normalizer neglect-able?).&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Having normal distribution in hand, we realize that it’s much easier to get log form and log function preserves monotonicity. Finally we have:
&lt;script type=&quot;math/tex&quot;&gt;-2logp(\theta) \sim (P\theta-q)'\Omega^{-1}(p\theta-q) + (\theta-\Pi)'\C(\theta-\Pi)\\
= please\ pick\ up\ your\ pen\ and\ multiply\ out\ the\ brackets\\
= \theta'(P'\Omega^{-1}P+C^{-1})\theta - 2(q'\Omega^{-1}P + \Pi'C^{-1})\theta\\
= \theta'H\theta - 2\eta\theta&lt;/script&gt;
For simplicity, let $H = P’\Omega^{-1}P+C^{-1}$ and $\eta = q’\Omega^{-1}P + \Pi’C^{-1}$&lt;/p&gt;

&lt;p&gt;Now, think about how we get mean and covariance of $\theta$
&lt;script type=&quot;math/tex&quot;&gt;logp(\theta) \approx c + \frac{(\theta-\mu)^2}{\sigma^2},\ c\ being\ some\ constant\\
\approx \frac{\theta^2}{\sigma^2} + \frac{2\theta\mu}{\sigma^2}\ (omitting\ terms\ without\ \theta)\                  (4)&lt;/script&gt;
It’s then clear that $H = \frac{1}{\sigma^2}\ and\ \eta = \frac{\mu}{\sigma^2} $ so we have covariance equals to $H^{-1}$ and mean equals $H^{-1}\eta$ .&lt;/p&gt;

&lt;h6 id=&quot;posterior-of-r&quot;&gt;Posterior of r&lt;/h6&gt;

&lt;p&gt;Well at this stage, I bet my readers already know the derivation for this one. Thanks to conjugate prior, we will be able to maintain the same update format as $\theta$.&lt;/p&gt;

&lt;p&gt;let $\xi = H^{-1}\eta, v = H^{-1}$, hence 
&lt;script type=&quot;math/tex&quot;&gt;p(r|q) \sim N(r|P\theta,\Omega) * N(\theta|\xi,v)&lt;/script&gt;
Similarly, we let $H_r = V^{-1} + p’\Omega^{-1}P, \eta’_r =\xi’V^{-1} + r’\Omega^{-1}P$, and one more term $z = r’\Omega^{-1}r + \xi’V^{-1}\xi$&lt;/p&gt;

&lt;p&gt;and using the same trick, we get 
&lt;script type=&quot;math/tex&quot;&gt;\mathbb{E}(r) = (\Omega^{-1}+\Omega^-1PH_r^{-1}P'\Omega^{-1})^{-1}\Omega^{-1}PH_r^{-1}V^{-1}\xi\\
\mathbb{V}(r) = (\Omega^{-1}+\Omega^{-1}PH_r^{-1}P'\Omega^{-1})^{-1}&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Recall our portfolio set up, we can now obtain optimal portfolio holding
&lt;script type=&quot;math/tex&quot;&gt;h_{opt} = (k\mathbb{V}(r))^{-1}\mathbb{R}(r)&lt;/script&gt;&lt;/p&gt;

&lt;h6 id=&quot;end-note&quot;&gt;End Note&lt;/h6&gt;

&lt;p&gt;Originally I imagined putting everything in one post, but while writing it I decided it’s best to follow the structure of most generalized derivation -&amp;gt; introduction of arbitrage pricing theory model -&amp;gt; application, from dataset specs to code. So stay tuned for the following posts in this series!&lt;/p&gt;</content><author><name></name></author><summary type="html">The beauty of mathematics, to me, lies the most in the ability of substantiating abstract ideas. One of my favorite to name is the orbit-stabilizer theorem (imaginable as a cube with orbit and you can flip it by rules).</summary></entry><entry><title type="html">Bayesian Struggles: why we need conjugate priors</title><link href="//numerairx.github.io/Bayesian-Struggles-Why-We-Need-Conjugate-Prior/" rel="alternate" type="text/html" title="Bayesian Struggles: why we need conjugate priors" /><published>2018-12-22T00:00:00-05:00</published><updated>2018-12-22T00:00:00-05:00</updated><id>//numerairx.github.io/Bayesian%20Struggles-Why-We-Need-Conjugate-Prior</id><content type="html" xml:base="//numerairx.github.io/Bayesian-Struggles-Why-We-Need-Conjugate-Prior/">&lt;p&gt;I want to start this first post of the series of Bayesian stats with this meme.
&lt;a href=&quot;//numerairX.github.io/images/bayesfun.png&quot;&gt;&lt;img src=&quot;//numerairX.github.io/images/bayesfun.png&quot; alt=&quot;bayesian meme&quot; /&gt;&lt;/a&gt;&lt;br /&gt;
(image from &lt;a href=&quot;https://www2.isye.gatech.edu/~brani/isyebayes/jokes.html&quot;&gt;Bayesian Fun&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;It is also important to make sure my dear reader(s) knows that I am by all means not an expert in statistics (let me know if u found mistakes!). I came from an applied math background but had no interest in taking stats in college (thought it was easy and too formulaic at that time, naive!!). So I am almost completely self-taught in this subject and prone to interpret things in a familiar way to help me understand.&lt;/p&gt;

&lt;p&gt;However, I  think because I had (a lot of) struggles, I can share better how the logic flows to overcome them.&lt;/p&gt;

&lt;h3 id=&quot;how-did-we-come-to-realize-that-we-might-need-something-called-conjugate-prior&quot;&gt;How did we come to realize that we might need something called conjugate prior?&lt;/h3&gt;

&lt;p&gt;Consider the example given by Bayes himself in his 1763 paper: let us roll a ball along unit interval $[0,1]$ with uniform probability of stopping anywhere in between. 
This ball finally stopped at distance $\theta$ and we then throw this ball for $n$ times. Denote the number of times ball stops before reaching 
$\theta$ as $x$, what can we learn about $\theta$ now (aka what is $p(\theta|x)$)?&lt;/p&gt;

&lt;p&gt;In this case our prior is no longer just our &lt;em&gt;‘belief’&lt;/em&gt; but a physics fact. We understand that $p(\theta)$ is 1 since it follows uniform distribution, 
and $p(x|\theta)$ is just binomial probability density function.&lt;/p&gt;

&lt;p&gt;$p(x|\theta)=$
$           \int_{0}^{1}\theta^x(1-\theta)^{n-x}d\theta$&lt;/p&gt;

&lt;p&gt;$           =\frac{1^{k+1}(1-1)^{n-k}}{k+1}-\frac{0^{k+1}(1-0)^{n-k}}{k+1}$&lt;/p&gt;

&lt;p&gt;$             +\frac{n-k}{k+1}\int_0^1 p^{k+1}(1-p)^{n-k-1}$&lt;/p&gt;

&lt;p&gt;$           =  …$ keep doing integration by parts&lt;/p&gt;

&lt;p&gt;$           = \frac{x!(n-x)!}{(n+1)!}$&lt;/p&gt;

&lt;p&gt;which verifies to be beta distribution of $\alpha = x+1, \beta = n-x+1$.&lt;/p&gt;

&lt;p&gt;With all the elements known, by Baye’s theorem $p(\theta|x) \propto p(x|\theta)p(\theta) $, our posterior follows beta distribution of the above parameters.
However, if instead we take $Beta(\alpha,\beta)$ as our prior, our posterior then follows:
$p(x|\theta)p(\theta) \propto \theta^x(1-\theta)^{n-x}\theta^{\alpha-1}(1-\theta)^{\beta-1} \sim Beta(\alpha+x,\beta+n-x)$.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;highlight&lt;/em&gt;:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;our posterior has the same form as prior which makes it easy to update&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;prior now also have explanation power:&lt;/p&gt;

    &lt;p&gt;while we roll the ball, each time it stops before $\theta$, it corresponds to the probability density of binomial as in increase of successful trail (aka $x+1$),
so imagine if we were live-recording the rolling, we would add 1 to $\alpha$.  If it exceeds the line, we would add 1 to $\beta$.  Very intuitive.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;did-that-really-make-much-of-a-difference-yes-if-we-bring-complicated-integrals-in-the-house&quot;&gt;Did that really make much of a difference? Yes if we bring complicated integrals in the house!&lt;/h4&gt;

&lt;p&gt;let’s imagine a slightly more complicated case, where you are trying to infer the parameters of your dataset, which you believe to follow normal distribution. 
You don’t get nice property like $p(\theta)$ just equals to 1 and needs to do&lt;br /&gt;
$\int_{- \infty}^{\infty} \frac{1}{\sqrt{2\pi\sigma_0^2}} e^{\frac{-(\mu-\mu_0)^2}{2\sigma_0^2}} * \frac{1}{\sqrt{2\pi\sigma^2}} e^{\frac{-(x-\mu)^2}{2\sigma^2}} d\mu$
 every time you update. This is actually why most times we want find nice conjugate priors to avoid computing high dimensional integration. The benefits will came clear after the below explanation.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Consider i.i.d sample $X = (x_1,x_2, …, x_n)$ are drawn from distribution  $N(\mu,\sigma^2)$ with &lt;strong&gt;$\mu$ and $\sigma^2$ random&lt;/strong&gt;. Let $\tau = \frac{1}{\sigma^2}$, it is suffice to have parameter set $\theta = (\mu, \tau)$.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&quot;our-goal-find-pxmutau&quot;&gt;Our goal: find $p(x|\mu,\tau)$&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Tricky part: find $p(\mu,\tau)$
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Similarly to the problem of only $\sigma^2$ fixed, consider a gamma prior, $\tau \propto \Gamma(\alpha,\beta) $, and we use the parametrization that PDF is $ \frac{\beta^\alpha}{\Gamma(\alpha)} x^{\alpha-1} e^{-x\beta}$ then for $\sigma^2$ is (obviously) an inverse gamma distribution, aka $\sigma^2 \propto IG(\alpha,\beta)$.&lt;/p&gt;

&lt;p&gt;However, I did struggle a while understanding what $\mu$ should be because it seems independent of $\sigma^2$. 
But if $\mu$ and $\sigma^2$ are independent of each other, posterior won’t be in inverse gamma format so we end up having nothing handy. 
Later from the wisdom of my professor, he made that $\mu|\tau \propto N(v, \frac{1}{k\tau})$ for $v, k$ being some real number and of course $k&amp;gt;0$. 
The reason behind is given both conditioned on $X$ , $\mu$ and $\sigma^2$ should be dependent.&lt;/p&gt;

&lt;p&gt;The full prior density $p(\tau,\mu)$ is then $p(\tau)p(\mu|\tau)$
$ = \frac{\beta^\alpha}{\Gamma(\alpha)} x^{\alpha-1} e^{(-x\beta)} \sqrt{\frac{k\tau}{2\pi}} e^{({-\frac{k\tau}{2}(\mu-v)^2})}$ &lt;strong&gt;(1)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;and posterior $p(\mu,\tau|x)$
           = &lt;em&gt;(1)&lt;/em&gt; x $(\frac{\tau}{2\pi})^{\frac{n}{2}}e^{({\frac{-\tau}{2}}\sum_{i}(x_i-\mu)^2)}$&lt;/p&gt;

&lt;p&gt;Omitting some merging and substituting tricks that nobody wants to see, we come down to $p(\mu,\tau|x)$
$\propto\tau^{\alpha’-1/2}e^{(-\tau(\beta’ + \frac{k’}{2}(\mu-v’)^2))}$&lt;/p&gt;

&lt;p&gt;$\alpha’ = \alpha + \frac{n}{2}$&lt;/p&gt;

&lt;p&gt;$\beta’ = \beta + \frac{1}{2} \frac{nk}{n+k}(\bar{x}-v)^2 + \frac{1}{2} \sum_{i} (x_i-x)^2$&lt;/p&gt;

&lt;p&gt;$k’ = k+n’$&lt;/p&gt;

&lt;p&gt;$v’ = \frac{kv+n\bar{x}}{k+n}$&lt;/p&gt;

&lt;p&gt;leaves only four simple algebra to maintain at each update.&lt;/p&gt;

&lt;p&gt;To end this article, I will share a fun read, &lt;a href=&quot;http://www.stats.org.uk/priors/noninformative/YangBerger1998.pdf&quot;&gt;A Catalog of Noninformative Priors&lt;/a&gt; I found a while ago.&lt;/p&gt;</content><author><name></name></author><category term="statistics" /><summary type="html">starting with two simple examples...</summary></entry><entry><title type="html">2018 Paper and Book Reading List</title><link href="//numerairx.github.io/paper-recommendation/" rel="alternate" type="text/html" title="2018 Paper and Book Reading List" /><published>2018-12-09T00:00:00-05:00</published><updated>2018-12-09T00:00:00-05:00</updated><id>//numerairx.github.io/paper-recommendation</id><content type="html" xml:base="//numerairx.github.io/paper-recommendation/">&lt;p&gt;2018 is coming to an end, and by the end of this year I picked up a new hobby - answering quesitons on stack exchange (more specifically on &lt;a href=&quot;https://quant.stackexchange.com/&quot;&gt;quant fiance&lt;/a&gt;). It appears that a lot of times I see questions iterating over the same idea, and it made me wonder what if we can have a list of paper recommendations for anyone interested in quant finance, to start from the essentials and build a good foundation.&lt;/p&gt;

&lt;p&gt;So I decided to open this blog and share my reserves and interests with the folks. As a easy start, I will give a recommended reading list for understanding basics in some subfields of quant finance, and deeper digging in fixed income and market microstrucutre (I’m more focused on these).&lt;/p&gt;

&lt;p&gt;You’ll find in this article:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Modern Portfolio Management&lt;/li&gt;
  &lt;li&gt;Execution&lt;/li&gt;
  &lt;li&gt;Fixed Income&lt;/li&gt;
  &lt;li&gt;Machine Learning - general&lt;/li&gt;
  &lt;li&gt;Market Making and Microstructure&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;**disclamer: I won’t write recommendatin reason for all&lt;/p&gt;

&lt;h2 id=&quot;modern-portfolio-management&quot;&gt;Modern portfolio management&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;Active Portfolio Management: A Quantitative Approach for Producing Superior Returns and Selecting Superior Money Managers.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Reason&lt;/strong&gt;: If it is not THE book in this area. Was recommended by my professor Gordon Ritter (who recently won the buyside quant of the year, woah!!), for the class active portfolio management. Starting with CAPM, it goes deeper to how and what to attribute your return to. With this you’ll have the foundation on how to use basic regression in your portfolio for performance. It is mathematically straightforward and very easy to follow (understanding of linear algebra is sufficient I’d say).&lt;/p&gt;

&lt;h2 id=&quot;execution&quot;&gt;Execution&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=3DF6A80EC589C258C238ACA68F065873?doi=10.1.1.421.4916&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;Execution strategies in fixed income markets&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.math.nyu.edu/faculty/chriss/optliq_f.pdf&quot;&gt;Optimal execution of portfolio transactions&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3057570&quot;&gt;Optimal Microstructure Trading with a Long-Term Utility Function&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Reason&lt;/strong&gt;: the first and second cover the 3rd generation foundation of optimal execution by Almgren, a must read. Third one is built upon on the previous and talks about maintaining neutrality while executing a market neutral portfolio.&lt;/p&gt;

&lt;h2 id=&quot;fixed-income-trading&quot;&gt;Fixed Income Trading:&lt;/h2&gt;
&lt;p&gt;Pricing related:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2438623&quot;&gt;Affine principal component term structure model&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2451130&quot;&gt;A principal-component-based affine term structure model&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.kurims.kyoto-u.ac.jp/EMIS/journals/HOA/JAMDS/8/11.pdf&quot;&gt;Three ways to solve for bond prices in the vasicek model&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Trading in general:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;http://pages.stern.nyu.edu/~dbackus/BCZ/HS/BoxTiao_canonical_Bio_77.pdf&quot;&gt;A canonical analysis of multiple time series&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.cass.city.ac.uk/__data/assets/pdf_file/0004/128083/Large.pdf&quot;&gt;Pro-rata matching in one-tick markets&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.di.ens.fr/~aspremon/PDF/MeanRevVec.pdf&quot;&gt;Identifying small mean reverting portfolios&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2054689&quot;&gt;Estimating the yield curve using the Nelson-Siegel model, a ridge regression approach&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.mitpressjournals.org/doi/abs/10.1162/003465399558382?journalCode=rest&quot;&gt;Stochastic permanent breaks&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Reason:&lt;/strong&gt; some of the basics on pricing futures and forwards, what’s the most famous way to approximate PDE in fixed income pricing, and reducing colinearlity. In trading, fixed income sees a lot of pairs trading strategy so I think it’s essential to understand how the market works, and what pairs trading originated from to what problems you need to pay attention to while implementing.&lt;/p&gt;

&lt;h2 id=&quot;machine-learning--general&quot;&gt;Machine Learning – general:&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;Elements of statistical learning&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://pdfs.semanticscholar.org/9d07/cb2ffec8f5b63d6a329dec5b88987776303e.pdf&quot;&gt;Comparison of three evoluntionary algorithms: GA, PSO, and DE&lt;/a&gt;
Market Making and Microstrucure:&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Reason:&lt;/strong&gt; I can’t say enough how much I love the elements of statistical learning. Actually, whenever someone approaches me and asks what he/she should read as a intro to machine learning, I would recommend this right away if they have some quantitative background. Start with this book and stick only to it will save you tremendous amount of time going through meaningless, souless “machine learning” books that won’t even tell you how to infer on your parameters.&lt;/p&gt;

&lt;h2 id=&quot;market-making-and-microstrucutre&quot;&gt;Market Making and Microstrucutre&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1804.04216&quot;&gt;Market making via reinforcement learning&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://quantitativebrokers.com/wp-content/uploads/2017/05/Oct15-BTec1.pdf&quot;&gt;Cash Treasuries vs Futures on October 15, 2014&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.139.1085&amp;amp;rep=rep1&amp;amp;type=pdf&quot;&gt;A stochastic model for order book dynamics&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1202.6412&quot;&gt;Order book dynamics in liquid markets: limit theorems and diffusion approximations&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2970694&quot;&gt;The micro price: a high frequency estimator of future prices&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://users.iems.northwestern.edu/~armbruster/2007msande444/Hewlett2006%20price%20impact.pdf&quot;&gt;Clustering of order arrivals, price impact and trade path optimization&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Reason:&lt;/strong&gt; Most of the researches are on limit order book structures, and are targeted at buy side firms who want to figure out what their sell sides are calculating. However in the similar way it can be applied in sell side, e.g. model your client’s order arrival in a hawkes model!&lt;/p&gt;

&lt;p&gt;That’d be all for now.&lt;/p&gt;

&lt;hr /&gt;</content><author><name></name></author><category term="Paper recommendation" /><summary type="html">especially if you're interested in fixed income and market microstructure...</summary></entry></feed>